[project]
name = "gpt_server"
version = "0.3.6"
description = "gpt_server是一个用于生产级部署LLMs或Embedding的开源框架。"
readme = "README.md"
license = { text = "Apache 2.0" }
authors = [{ name = "Yu Liu", email = "506610466@qq.com" }]
requires-python = ">=3.10"
dependencies = [
    "accelerate>=1.0.1",
    "fastapi==0.114.1",
    "ffmpy",
    "fschat==0.2.36",
    "gradio==4.26.0",
    "infinity-emb[all]==0.0.73",
    "lmdeploy==0.7.0.post3",
    "loguru>=0.7.2",
    "openai==1.55.3",
    "setuptools==75.2.0",
    "streamlit==1.39.0",
    "torch==2.5.1",
    "torchvision==0.20.1",
    "transformers==4.48.2",
    "vllm==0.7.2",
    "qwen_vl_utils",
    "evalscope[perf]==0.10.1",
    "modelscope==1.20.1",
    "edge-tts>=7.0.0",
]

[tool.uv]
override-dependencies = [
    "setuptools==75.2.0",
    "torchvision==0.20.1",
    "torch==2.5.1",
    "triton",
    "outlines==0.1.11",
    "pynvml==12.0.0" # 解决vllm==0.7.2的bug https://github.com/vllm-project/vllm/issues/12847，后面可去掉

]

[[tool.uv.index]]
url = "https://pypi.tuna.tsinghua.edu.cn/simple"
default = true

[project.scripts]
gpt_server = "gpt_server.cli:main"

[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"
